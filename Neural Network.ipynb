{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d854389a-7f46-43de-aea5-3de7076313c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba04a83e-a9e4-4125-9743-9f9a3d9bfd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed dataset\n",
    "df_clean = pd.read_csv('churn_processed.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = df_clean.drop('Exited', axis=1)\n",
    "y = df_clean['Exited']\n",
    "\n",
    "# Split the data into training and test sets (70% train, 30% test) - same as previous tasks\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature scaling - crucial for neural networks\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed145ba-cf79-4949-bbe4-83ade8a422b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Neural Network (MLP)\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,), (20,), (50,), (100,), (10, 10), (20, 10)],  # Network architecture\n",
    "    'activation': ['relu', 'tanh'],                                         # Activation function\n",
    "    'alpha': [0.0001, 0.001, 0.01],                                         # L2 regularization\n",
    "    'learning_rate_init': [0.001, 0.01],                                    # Initial learning rate\n",
    "    'max_iter': [200, 500]                                                  # Maximum iterations\n",
    "}\n",
    "\n",
    "# Explanation of hyperparameters:\n",
    "# Hyperparameter search explanation\n",
    "# hidden_layer_sizes: Defines the architecture (neurons in each hidden layer\n",
    "# activation: Activation function for hidden layers (relu = Rectified Linear Unit, tanh = Hyperbolic Tangent)\n",
    "# alpha: L2 regularization parameter to prevent overfitting\n",
    "# learning_rate_init: Initial learning rate for weight updates\n",
    "# max_iter: Maximum number of iterations for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fa00fa-a754-46d3-8abd-639306d0a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object for neural network\n",
    "grid_search_nn = GridSearchCV(\n",
    "    estimator=MLPClassifier(random_state=42, early_stopping=True, validation_fraction=0.1, verbose=True),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                    # 3-fold cross-validation (reduced from 5 since NN is computationally intensive)\n",
    "    scoring='accuracy',      # Use accuracy as the scoring metric\n",
    "    n_jobs=-1,               # Use all available CPU cores\n",
    "    verbose=1                # Show progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5984f7b9-ea1e-4cba-b785-cfb061c58a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Grid Search for Neural Network optimization...\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "Iteration 1, loss = 0.40487021\n",
      "Validation score: 0.952857\n",
      "Iteration 2, loss = 0.13453731\n",
      "Validation score: 0.957143\n",
      "Iteration 3, loss = 0.11148727\n",
      "Validation score: 0.957143\n",
      "Iteration 4, loss = 0.10754915\n",
      "Validation score: 0.955714\n",
      "Iteration 5, loss = 0.10670289\n",
      "Validation score: 0.955714\n",
      "Iteration 6, loss = 0.10583234\n",
      "Validation score: 0.955714\n",
      "Iteration 7, loss = 0.10529085\n",
      "Validation score: 0.955714\n",
      "Iteration 8, loss = 0.10462780\n",
      "Validation score: 0.955714\n",
      "Iteration 9, loss = 0.10357457\n",
      "Validation score: 0.955714\n",
      "Iteration 10, loss = 0.10323840\n",
      "Validation score: 0.955714\n",
      "Iteration 11, loss = 0.10287716\n",
      "Validation score: 0.955714\n",
      "Iteration 12, loss = 0.10249774\n",
      "Validation score: 0.955714\n",
      "Iteration 13, loss = 0.10185335\n",
      "Validation score: 0.955714\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "Best Parameters:\n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01, 'max_iter': 200}\n"
     ]
    }
   ],
   "source": [
    "# Perform the grid search\n",
    "print(\"\\nStarting Grid Search for Neural Network optimization...\")\n",
    "grid_search_nn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(grid_search_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5565f9d-673b-4fb6-aba0-f23d4ddc466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Performance:\n",
      "Training Accuracy: 0.9704\n",
      "Test Accuracy: 0.9660\n"
     ]
    }
   ],
   "source": [
    "# Use the best model\n",
    "nn_best = grid_search_nn.best_estimator_\n",
    "\n",
    "# Evaluate on training and test sets\n",
    "y_train_pred_nn = nn_best.predict(X_train_scaled)\n",
    "y_test_pred_nn = nn_best.predict(X_test_scaled)\n",
    "\n",
    "train_accuracy_nn = accuracy_score(y_train, y_train_pred_nn)\n",
    "test_accuracy_nn = accuracy_score(y_test, y_test_pred_nn)\n",
    "\n",
    "print(\"\\nNeural Network Performance:\")\n",
    "print(f\"Training Accuracy: {train_accuracy_nn:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce35aed7-7783-4884-ba25-ca253f00bf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overfitting Check:\n",
      "Accuracy difference (Train - Test): 0.0044\n",
      "No strong evidence of overfitting: Training and test accuracies are similar\n"
     ]
    }
   ],
   "source": [
    "# Check for overfitting\n",
    "print(\"\\nOverfitting Check:\")\n",
    "print(f\"Accuracy difference (Train - Test): {train_accuracy_nn - test_accuracy_nn:.4f}\")\n",
    "if train_accuracy_nn - test_accuracy_nn > 0.05:\n",
    "    print(\"Possible overfitting: Training accuracy is significantly higher than test accuracy\")\n",
    "else:\n",
    "    print(\"No strong evidence of overfitting: Training and test accuracies are similar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da665bb2-1b7c-4fe5-aab9-4243ea9da9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convergence Check:\n",
      "Best model iterations: 13\n",
      "Maximum iterations allowed: 200\n",
      "The model converged before reaching maximum iterations\n"
     ]
    }
   ],
   "source": [
    "# Check convergence\n",
    "print(\"\\nConvergence Check:\")\n",
    "print(f\"Best model iterations: {nn_best.n_iter_}\")\n",
    "print(f\"Maximum iterations allowed: {nn_best.max_iter}\")\n",
    "if nn_best.n_iter_ < nn_best.max_iter:\n",
    "    print(\"The model converged before reaching maximum iterations\")\n",
    "else:\n",
    "    print(\"The model reached maximum iterations without convergence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a90752d0-9c0a-4406-8f4f-6b0ecc59b4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Neural Network architecture:\n",
      "Hidden layer sizes: (10,)\n",
      "Activation function: tanh\n",
      "Alpha (L2 regularization): 0.0001\n",
      "Learning rate: 0.01\n",
      "Solver: adam\n"
     ]
    }
   ],
   "source": [
    "# Display model details\n",
    "print(\"\\nBest Neural Network architecture:\")\n",
    "print(f\"Hidden layer sizes: {nn_best.hidden_layer_sizes}\")\n",
    "print(f\"Activation function: {nn_best.activation}\")\n",
    "print(f\"Alpha (L2 regularization): {nn_best.alpha}\")\n",
    "print(f\"Learning rate: {nn_best.learning_rate_init}\")\n",
    "print(f\"Solver: {nn_best.solver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170a385e-64d6-4d39-86b2-34980ca1c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top features from best decision tree model:\n",
      "- ComplaintsLodged\n",
      "- Age\n",
      "- NumOfProducts\n",
      "\n",
      "Reduced dataset prepared:\n",
      "Training set shape: (7000, 3)\n",
      "Test set shape: (3000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get the top 5 features from the best decision tree model (Task 2)\n",
    "top_dt_features = ['ComplaintsLodged', 'Age', 'NumOfProducts']\n",
    "\n",
    "print(\"\\nTop features from best decision tree model:\")\n",
    "for feature in top_dt_features:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "# Create reduced dataset with only these features\n",
    "X_train_reduced = X_train[top_dt_features]\n",
    "X_test_reduced = X_test[top_dt_features]\n",
    "\n",
    "# Apply scaling to the reduced feature set\n",
    "X_train_reduced_scaled = scaler.fit_transform(X_train_reduced)\n",
    "X_test_reduced_scaled = scaler.transform(X_test_reduced)\n",
    "\n",
    "print(\"\\nReduced dataset prepared:\")\n",
    "print(f\"Training set shape: {X_train_reduced_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_reduced_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25f91878-ea5f-4a77-a7f4-1e2fc0f9ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for reduced neural network\n",
    "param_grid_reduced = {\n",
    "    'hidden_layer_sizes': [(5,), (10,), (20,), (5, 5), (10, 5)],  # Smaller architectures for fewer inputs\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'max_iter': [200, 500]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aac1a7e9-2576-4ede-98e6-5979aa35b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object for reduced neural network\n",
    "grid_search_nn_reduced = GridSearchCV(\n",
    "    estimator=MLPClassifier(random_state=42, early_stopping=True, validation_fraction=0.1),\n",
    "    param_grid=param_grid_reduced,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bab2c9-73ac-4937-8021-d51b9afb039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Grid Search for reduced Neural Network...\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    }
   ],
   "source": [
    "# Perform the grid search on reduced feature set\n",
    "print(\"\\nStarting Grid Search for reduced Neural Network...\")\n",
    "grid_search_nn_reduced.fit(X_train_reduced_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "print(\"\\nBest Parameters for reduced Neural Network:\")\n",
    "print(grid_search_nn_reduced.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb427cb-94f8-4dc7-a15c-7c6e01472f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best reduced model\n",
    "nn_reduced_best = grid_search_nn_reduced.best_estimator_\n",
    "\n",
    "# Evaluate on training and test sets\n",
    "y_train_pred_nn_reduced = nn_reduced_best.predict(X_train_reduced_scaled)\n",
    "y_test_pred_nn_reduced = nn_reduced_best.predict(X_test_reduced_scaled)\n",
    "\n",
    "train_accuracy_nn_reduced = accuracy_score(y_train, y_train_pred_nn_reduced)\n",
    "test_accuracy_nn_reduced = accuracy_score(y_test, y_test_pred_nn_reduced)\n",
    "\n",
    "print(\"\\nReduced Neural Network Performance:\")\n",
    "print(f\"Training Accuracy: {train_accuracy_nn_reduced:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_nn_reduced:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fccbb4c-d322-4c5e-85b8-64e99d8586e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overfitting in reduced model\n",
    "print(\"\\nOverfitting Check for reduced model:\")\n",
    "print(f\"Accuracy difference (Train - Test): {train_accuracy_nn_reduced - test_accuracy_nn_reduced:.4f}\")\n",
    "if train_accuracy_nn_reduced - test_accuracy_nn_reduced > 0.05:\n",
    "    print(\"Possible overfitting: Training accuracy is significantly higher than test accuracy\")\n",
    "else:\n",
    "    print(\"No strong evidence of overfitting: Training and test accuracies are similar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af0e0b-c34f-4cf6-99ab-8192ff0e7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check convergence of reduced model\n",
    "print(\"\\nConvergence Check for reduced model:\")\n",
    "print(f\"Reduced model iterations: {nn_reduced_best.n_iter_}\")\n",
    "print(f\"Maximum iterations allowed: {nn_reduced_best.max_iter}\")\n",
    "if nn_reduced_best.n_iter_ < nn_reduced_best.max_iter:\n",
    "    print(\"The reduced model converged before reaching maximum iterations\")\n",
    "else:\n",
    "    print(\"The reduced model reached maximum iterations without convergence\")\n",
    "\n",
    "# Display reduced model details\n",
    "print(\"\\nReduced Neural Network architecture:\")\n",
    "print(f\"Hidden layer sizes: {nn_reduced_best.hidden_layer_sizes}\")\n",
    "print(f\"Activation function: {nn_reduced_best.activation}\")\n",
    "print(f\"Alpha (L2 regularization): {nn_reduced_best.alpha}\")\n",
    "print(f\"Learning rate: {nn_reduced_best.learning_rate_init}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb58aa-046b-41f2-98ec-4a74c445f129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c9e5f7-90ed-4ebe-8049-17ac6794a8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0c114-62b8-48fe-bc8f-d0673f0f026a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2efd55-ac1c-4716-9e42-563a04d6d7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f668c5f6-9432-4d3f-8de0-cccd3bd43a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
